import cv2,torch
from ultralytics import YOLO
model = YOLO("yolo11n.pt")
image = cv2.imread('bus.jpg')
results = model(image)
annotated_image = results[0].plot()
cv2.imshow('Image', annotated_image)
cv2.waitKey(0);cv2.destroyAllWindows()
import cv2
from ultralytics import YOLO
model = YOLO("yolo11n.pt");cap = cv2.VideoCapture(0)
while cap.isOpened():
    success, frame = cap.read()
    if success:
        results = model(frame)
        annotated_frame = results[0].plot()
        cv2.imshow("YOLO Inference", annotated_frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):break
    else:break
cap.release();cv2.destroyAllWindows()
from ultralytics import YOLO
model = YOLO("yolo11n-seg.pt")
image = cv2.imread('bus.jpg')
results = model(image)
annotated_image = results[0].plot()
cv2.imshow('Image', annotated_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
import cv2
from ultralytics import YOLO
model = YOLO("yolo11n-seg.pt")
cap = cv2.VideoCapture(0)
while cap.isOpened():
    success, frame = cap.read()
    if success:
        results = model(frame)
        annotated_frame = results[0].plot()
        cv2.imshow("YOLO Inference", annotated_frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):break
    else:break
cap.release()
cv2.destroyAllWindows()
from ultralytics import YOLO
from collections import defaultdict
import numpy,cv2
model = YOLO("yolo11n.pt")
video_path = "dogRun.mp4"
cap = cv2.VideoCapture(video_path)
track_history = defaultdict(lambda: [])
while cap.isOpened():
    success, frame = cap.read()
    if success:
        results = model.track(frame, persist=True)
        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xywh.cpu()
            track_ids = results[0].boxes.id.int().cpu().tolist()
            annotated_frame = results[0].plot()
            for box, track_id in zip(boxes, track_ids):
                x, y, w, h = box
                track = track_history[track_id]
                track.append((float(x), float(y)))
                if len(track) > 30:
                    track.pop(0)
                    points = numpy.array(track).astype(numpy.int32).reshape((-1, 1, 2))
                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=2)
                    cv2.imshow("YOLO Tracking", annotated_frame)
        else:cv2.imshow("YOLO Tracking", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):break
    else:break
cap.release()
cv2.destroyAllWindows()
from ultralytics import YOLO
from collections import defaultdict
import numpy,cv2
model = YOLO("yolo11n.pt")
cap = cv2.VideoCapture(0)
track_history = defaultdict(lambda: [])
while cap.isOpened():
    success, frame = cap.read()
    if success:
        results = model.track(frame, persist=True)
        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xywh.cpu()
            track_ids = results[0].boxes.id.int().cpu().tolist()
            annotated_frame = results[0].plot()
            for box, track_id in zip(boxes, track_ids):
                x, y, w, h = box
                track = track_history[track_id]
                track.append((float(x), float(y)))
                if len(track) > 30:
                        track.pop(0);points = numpy.array(track).astype(numpy.int32).reshape((-1, 1, 2))
                        cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=2)
                        cv2.imshow("YOLO Tracking", annotated_frame)
        else:cv2.imshow("YOLO Tracking", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):break
    else:break
cap.release()
cv2.destroyAllWindows()
import cv2
from ultralytics import YOLO
model = YOLO("yolo11n-pose.pt")
image = cv2.imread('bus.jpg')
results = model(image)
annotated_image = results[0].plot()
cv2.imshow('Image', annotated_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
import cv2
from ultralytics import YOLO
model = YOLO("yolo11n-pose.pt")
cap = cv2.VideoCapture(0)
while cap.isOpened():
    success, frame = cap.read()
    if success:
        results = model(frame)
        annotated_frame = results[0].plot()
        cv2.imshow("YOLO Inference", annotated_frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):break
    else:break
cap.release()
cv2.destroyAllWindows()
import cv2
from ultralytics import YOLO
model = YOLO("yolo11n-obb.pt")
image = cv2.imread('boats.jpg')
results = model(image)
annotated_image = results[0].plot()
cv2.imshow('Image', annotated_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
import cv2
from ultralytics import YOLO
model = YOLO("yolo11n-obb.pt")
cap = cv2.VideoCapture(0)
while cap.isOpened():
    success, frame = cap.read()
    if success:
        results = model(frame)
        annotated_frame = results[0].plot()
        cv2.imshow("YOLO Inference", annotated_frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):break
    else:break
cap.release()
cv2.destroyAllWindows()
